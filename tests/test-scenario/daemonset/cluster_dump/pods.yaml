apiVersion: v1
items:
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/limit-ranger: 'LimitRanger plugin set: cpu request for container
        hello'
    creationTimestamp: 2019-09-05T15:30:07Z
    generateName: foobar-wrong-1567697400-
    labels:
      controller-uid: 0a420fdd-cff2-11e9-98f3-42010a8000c4
      job-name: foobar-wrong-1567697400
    name: foobar-wrong-1567697400-7b4np
    namespace: default
    ownerReferences:
    - apiVersion: batch/v1
      blockOwnerDeletion: true
      controller: true
      kind: Job
      name: foobar-wrong-1567697400
      uid: 0a420fdd-cff2-11e9-98f3-42010a8000c4
    resourceVersion: "20987449"
    selfLink: /api/v1/namespaces/default/pods/foobar-wrong-1567697400-7b4np
    uid: 0a457b1c-cff2-11e9-98f3-42010a8000c4
  spec:
    containers:
    - command:
      - sleep
      - "600"
      image: bash
      imagePullPolicy: Always
      name: hello
      resources:
        requests:
          cpu: 100m
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-kchbk
        readOnly: true
    dnsPolicy: ClusterFirst
    nodeName: gke-tesg1-default-pool-ff7a1295-dmtd
    priority: 0
    restartPolicy: Never
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: default-token-kchbk
      secret:
        defaultMode: 420
        secretName: default-token-kchbk
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2019-09-05T15:30:07Z
      reason: PodCompleted
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2019-09-05T15:40:08Z
      reason: PodCompleted
      status: "False"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2019-09-05T15:40:08Z
      reason: PodCompleted
      status: "False"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: 2019-09-05T15:30:07Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://63252d48f5597e04587b9b5a7147a002db7de087cf46bf0a626e6de9f817733c
      image: bash:latest
      imageID: docker-pullable://bash@sha256:b7648de8f07dd0de784e19f058f3e30c4b2890ef7be3994b4226cdd194871d78
      lastState: {}
      name: hello
      ready: false
      restartCount: 0
      state:
        terminated:
          containerID: docker://63252d48f5597e04587b9b5a7147a002db7de087cf46bf0a626e6de9f817733c
          exitCode: 0
          finishedAt: 2019-09-05T15:40:08Z
          reason: Completed
          startedAt: 2019-09-05T15:30:08Z
    hostIP: 10.128.0.17
    phase: Succeeded
    podIP: 10.8.4.244
    qosClass: Burstable
    startTime: 2019-09-05T15:30:07Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/limit-ranger: 'LimitRanger plugin set: cpu request for container
        hello'
    creationTimestamp: 2019-09-05T15:35:07Z
    generateName: foobar-wrong-1567697700-
    labels:
      controller-uid: bd65e78e-cff2-11e9-98f3-42010a8000c4
      job-name: foobar-wrong-1567697700
    name: foobar-wrong-1567697700-zkpwz
    namespace: default
    ownerReferences:
    - apiVersion: batch/v1
      blockOwnerDeletion: true
      controller: true
      kind: Job
      name: foobar-wrong-1567697700
      uid: bd65e78e-cff2-11e9-98f3-42010a8000c4
    resourceVersion: "20988476"
    selfLink: /api/v1/namespaces/default/pods/foobar-wrong-1567697700-zkpwz
    uid: bd6980ec-cff2-11e9-98f3-42010a8000c4
  spec:
    containers:
    - command:
      - sleep
      - "600"
      image: bash
      imagePullPolicy: Always
      name: hello
      resources:
        requests:
          cpu: 100m
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-kchbk
        readOnly: true
    dnsPolicy: ClusterFirst
    nodeName: gke-tesg1-default-pool-ff7a1295-dmtd
    priority: 0
    restartPolicy: Never
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: default-token-kchbk
      secret:
        defaultMode: 420
        secretName: default-token-kchbk
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2019-09-05T15:35:07Z
      reason: PodCompleted
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2019-09-05T15:45:09Z
      reason: PodCompleted
      status: "False"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2019-09-05T15:45:09Z
      reason: PodCompleted
      status: "False"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: 2019-09-05T15:35:07Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://e00a7a5fe8e31b010a82e5b92e5f2d1e7106350617583016e3d647bbd8d9973a
      image: bash:latest
      imageID: docker-pullable://bash@sha256:b7648de8f07dd0de784e19f058f3e30c4b2890ef7be3994b4226cdd194871d78
      lastState: {}
      name: hello
      ready: false
      restartCount: 0
      state:
        terminated:
          containerID: docker://e00a7a5fe8e31b010a82e5b92e5f2d1e7106350617583016e3d647bbd8d9973a
          exitCode: 0
          finishedAt: 2019-09-05T15:45:08Z
          reason: Completed
          startedAt: 2019-09-05T15:35:08Z
    hostIP: 10.128.0.17
    phase: Succeeded
    podIP: 10.8.4.245
    qosClass: Burstable
    startTime: 2019-09-05T15:35:07Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/limit-ranger: 'LimitRanger plugin set: cpu request for container
        hello'
    creationTimestamp: 2019-09-05T15:40:08Z
    generateName: foobar-wrong-1567698000-
    labels:
      controller-uid: 708facd7-cff3-11e9-98f3-42010a8000c4
      job-name: foobar-wrong-1567698000
    name: foobar-wrong-1567698000-5ft9z
    namespace: default
    ownerReferences:
    - apiVersion: batch/v1
      blockOwnerDeletion: true
      controller: true
      kind: Job
      name: foobar-wrong-1567698000
      uid: 708facd7-cff3-11e9-98f3-42010a8000c4
    resourceVersion: "20989454"
    selfLink: /api/v1/namespaces/default/pods/foobar-wrong-1567698000-5ft9z
    uid: 7092ca50-cff3-11e9-98f3-42010a8000c4
  spec:
    containers:
    - command:
      - sleep
      - "600"
      image: bash
      imagePullPolicy: Always
      name: hello
      resources:
        requests:
          cpu: 100m
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-kchbk
        readOnly: true
    dnsPolicy: ClusterFirst
    nodeName: gke-tesg1-default-pool-ff7a1295-dmtd
    priority: 0
    restartPolicy: Never
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: default-token-kchbk
      secret:
        defaultMode: 420
        secretName: default-token-kchbk
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2019-09-05T15:40:08Z
      reason: PodCompleted
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2019-09-05T15:50:09Z
      reason: PodCompleted
      status: "False"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2019-09-05T15:50:09Z
      reason: PodCompleted
      status: "False"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: 2019-09-05T15:40:08Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://020f4285bbbec8186487f28c0cd2d077a0127e0a8dee8e363b97f9ce9402c813
      image: bash:latest
      imageID: docker-pullable://bash@sha256:b7648de8f07dd0de784e19f058f3e30c4b2890ef7be3994b4226cdd194871d78
      lastState: {}
      name: hello
      ready: false
      restartCount: 0
      state:
        terminated:
          containerID: docker://020f4285bbbec8186487f28c0cd2d077a0127e0a8dee8e363b97f9ce9402c813
          exitCode: 0
          finishedAt: 2019-09-05T15:50:09Z
          reason: Completed
          startedAt: 2019-09-05T15:40:09Z
    hostIP: 10.128.0.17
    phase: Succeeded
    podIP: 10.8.4.247
    qosClass: Burstable
    startTime: 2019-09-05T15:40:08Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/limit-ranger: 'LimitRanger plugin set: cpu request for container
        hello'
    creationTimestamp: 2019-09-05T15:45:09Z
    generateName: foobar-wrong-1567698300-
    labels:
      controller-uid: 23b937c6-cff4-11e9-98f3-42010a8000c4
      job-name: foobar-wrong-1567698300
    name: foobar-wrong-1567698300-b986p
    namespace: default
    ownerReferences:
    - apiVersion: batch/v1
      blockOwnerDeletion: true
      controller: true
      kind: Job
      name: foobar-wrong-1567698300
      uid: 23b937c6-cff4-11e9-98f3-42010a8000c4
    resourceVersion: "20988489"
    selfLink: /api/v1/namespaces/default/pods/foobar-wrong-1567698300-b986p
    uid: 23bcf022-cff4-11e9-98f3-42010a8000c4
  spec:
    containers:
    - command:
      - sleep
      - "600"
      image: bash
      imagePullPolicy: Always
      name: hello
      resources:
        requests:
          cpu: 100m
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-kchbk
        readOnly: true
    dnsPolicy: ClusterFirst
    nodeName: gke-tesg1-default-pool-ff7a1295-zpc5
    priority: 0
    restartPolicy: Never
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: default-token-kchbk
      secret:
        defaultMode: 420
        secretName: default-token-kchbk
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2019-09-05T15:45:09Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2019-09-05T15:45:12Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2019-09-05T15:45:12Z
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: 2019-09-05T15:45:09Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://ff5f743c5ad43d13221fd5e667cef73032e0c0ca15b1fe3a488bb0496ea37d1f
      image: bash:latest
      imageID: docker-pullable://bash@sha256:f4c9389dc2d458fdfed0ff57a0cefb33ca0ba8d53146cd94c2e8321cea7db2aa
      lastState: {}
      name: hello
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2019-09-05T15:45:11Z
    hostIP: 10.128.0.16
    phase: Running
    podIP: 10.8.3.74
    qosClass: Burstable
    startTime: 2019-09-05T15:45:09Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/limit-ranger: 'LimitRanger plugin set: cpu request for container
        hello'
    creationTimestamp: 2019-09-05T15:50:09Z
    generateName: foobar-wrong-1567698600-
    labels:
      controller-uid: d6dfbfd3-cff4-11e9-98f3-42010a8000c4
      job-name: foobar-wrong-1567698600
    name: foobar-wrong-1567698600-hms9c
    namespace: default
    ownerReferences:
    - apiVersion: batch/v1
      blockOwnerDeletion: true
      controller: true
      kind: Job
      name: foobar-wrong-1567698600
      uid: d6dfbfd3-cff4-11e9-98f3-42010a8000c4
    resourceVersion: "20989462"
    selfLink: /api/v1/namespaces/default/pods/foobar-wrong-1567698600-hms9c
    uid: d6e3ecd3-cff4-11e9-98f3-42010a8000c4
  spec:
    containers:
    - command:
      - sleep
      - "600"
      image: bash
      imagePullPolicy: Always
      name: hello
      resources:
        requests:
          cpu: 100m
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-kchbk
        readOnly: true
    dnsPolicy: ClusterFirst
    nodeName: gke-tesg1-default-pool-ff7a1295-zpc5
    priority: 0
    restartPolicy: Never
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: default-token-kchbk
      secret:
        defaultMode: 420
        secretName: default-token-kchbk
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2019-09-05T15:50:09Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2019-09-05T15:50:11Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2019-09-05T15:50:11Z
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: 2019-09-05T15:50:09Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://976eee29388a83578f0770e5fff1a3411eeee5dd48108b0c8ebb5a54b16d1c74
      image: bash:latest
      imageID: docker-pullable://bash@sha256:f4c9389dc2d458fdfed0ff57a0cefb33ca0ba8d53146cd94c2e8321cea7db2aa
      lastState: {}
      name: hello
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2019-09-05T15:50:10Z
    hostIP: 10.128.0.16
    phase: Running
    podIP: 10.8.3.75
    qosClass: Burstable
    startTime: 2019-09-05T15:50:09Z
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: 2019-08-31T01:51:54Z
    generateName: redis-master-57fc67768d-
    labels:
      app: redis
      pod-template-hash: 57fc67768d
      role: master
      tier: backend
    name: redis-master-57fc67768d-hl44k
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: redis-master-57fc67768d
      uid: 1fb98600-ae52-11e9-98f3-42010a8000c4
    resourceVersion: "19428192"
    selfLink: /api/v1/namespaces/default/pods/redis-master-57fc67768d-hl44k
    uid: e85c20ed-cb91-11e9-98f3-42010a8000c4
  spec:
    containers:
    - image: k8s.gcr.io/redis:e2e
      imagePullPolicy: IfNotPresent
      name: master
      ports:
      - containerPort: 6379
        protocol: TCP
      resources:
        requests:
          cpu: 100m
          memory: 100Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-kchbk
        readOnly: true
    dnsPolicy: ClusterFirst
    nodeName: gke-tesg1-default-pool-ff7a1295-nvv4
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: default-token-kchbk
      secret:
        defaultMode: 420
        secretName: default-token-kchbk
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2019-08-31T01:51:55Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2019-08-31T01:51:57Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2019-08-31T01:51:57Z
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: 2019-08-31T01:51:55Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://c906a8a65a780373fe6c4a43d696564bcaa27505dbb36847fc6b33cb191c5916
      image: k8s.gcr.io/redis:e2e
      imageID: docker-pullable://k8s.gcr.io/redis@sha256:f066bcf26497fbc55b9bf0769cb13a35c0afa2aa42e737cc46b7fb04b23a2f25
      lastState: {}
      name: master
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2019-08-31T01:51:57Z
    hostIP: 10.128.0.15
    phase: Running
    podIP: 10.8.2.105
    qosClass: Burstable
    startTime: 2019-08-31T01:51:55Z
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: 2019-09-05T15:40:29Z
    generateName: redis-master-evict-fd97bd94b-
    labels:
      app: redis-evict
      pod-template-hash: fd97bd94b
      role: master
      tier: backend
    name: redis-master-evict-fd97bd94b-n9ns6
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: redis-master-evict-fd97bd94b
      uid: 6ef1dd30-cf5a-11e9-98f3-42010a8000c4
    resourceVersion: "20989790"
    selfLink: /api/v1/namespaces/default/pods/redis-master-evict-fd97bd94b-n9ns6
    uid: 7cfe6351-cff3-11e9-98f3-42010a8000c4
  spec:
    containers:
    - image: k8s.gcr.io/redis:e2e
      imagePullPolicy: IfNotPresent
      name: master
      ports:
      - containerPort: 6379
        protocol: TCP
      resources:
        requests:
          cpu: 500m
          memory: 1700280Ki
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-kchbk
        readOnly: true
    dnsPolicy: ClusterFirst
    nodeName: gke-tesg1-default-pool-ff7a1295-zpc5
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: default-token-kchbk
      secret:
        defaultMode: 420
        secretName: default-token-kchbk
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2019-09-05T15:51:45Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2019-09-05T15:51:46Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2019-09-05T15:51:46Z
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: 2019-09-05T15:51:45Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://af337e336bc106230bda705b3d16db4f38438cf632392947b96881a622ca0327
      image: k8s.gcr.io/redis:e2e
      imageID: docker-pullable://k8s.gcr.io/redis@sha256:f066bcf26497fbc55b9bf0769cb13a35c0afa2aa42e737cc46b7fb04b23a2f25
      lastState: {}
      name: master
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2019-09-05T15:51:46Z
    hostIP: 10.128.0.16
    phase: Running
    podIP: 10.8.3.76
    qosClass: Burstable
    startTime: 2019-09-05T15:51:45Z
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: 2019-08-31T01:51:54Z
    generateName: redis-slave-57f9f8db74-
    labels:
      app: redis
      pod-template-hash: 57f9f8db74
      role: slave
      tier: backend
    name: redis-slave-57f9f8db74-bcnvr
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: redis-slave-57f9f8db74
      uid: 1fbf8bcb-ae52-11e9-98f3-42010a8000c4
    resourceVersion: "19428184"
    selfLink: /api/v1/namespaces/default/pods/redis-slave-57f9f8db74-bcnvr
    uid: e8e1ce44-cb91-11e9-98f3-42010a8000c4
  spec:
    containers:
    - env:
      - name: GET_HOSTS_FROM
        value: dns
      image: gcr.io/google_samples/gb-redisslave:v1
      imagePullPolicy: IfNotPresent
      name: slave
      ports:
      - containerPort: 6379
        protocol: TCP
      resources:
        requests:
          cpu: 100m
          memory: 100Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-kchbk
        readOnly: true
    dnsPolicy: ClusterFirst
    nodeName: gke-tesg1-default-pool-ff7a1295-dmtd
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: default-token-kchbk
      secret:
        defaultMode: 420
        secretName: default-token-kchbk
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2019-08-31T01:51:55Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2019-08-31T01:51:57Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2019-08-31T01:51:57Z
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: 2019-08-31T01:51:55Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://fa5045eb5e41c3144f9750363d4ad56151b4899c4b09d36716233696e8ae9808
      image: gcr.io/google_samples/gb-redisslave:v1
      imageID: docker-pullable://gcr.io/google_samples/gb-redisslave@sha256:90f62695e641e1a27d1a5e0bbb8b622205a48e18311b51b0da419ffad24b9016
      lastState: {}
      name: slave
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2019-08-31T01:51:56Z
    hostIP: 10.128.0.17
    phase: Running
    podIP: 10.8.4.150
    qosClass: Burstable
    startTime: 2019-08-31T01:51:55Z
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: 2019-08-31T01:51:54Z
    generateName: redis-slave-57f9f8db74-
    labels:
      app: redis
      pod-template-hash: 57f9f8db74
      role: slave
      tier: backend
    name: redis-slave-57f9f8db74-l6sf8
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: redis-slave-57f9f8db74
      uid: 1fbf8bcb-ae52-11e9-98f3-42010a8000c4
    resourceVersion: "19428189"
    selfLink: /api/v1/namespaces/default/pods/redis-slave-57f9f8db74-l6sf8
    uid: e8619678-cb91-11e9-98f3-42010a8000c4
  spec:
    containers:
    - env:
      - name: GET_HOSTS_FROM
        value: dns
      image: gcr.io/google_samples/gb-redisslave:v1
      imagePullPolicy: IfNotPresent
      name: slave
      ports:
      - containerPort: 6379
        protocol: TCP
      resources:
        requests:
          cpu: 100m
          memory: 100Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-kchbk
        readOnly: true
    dnsPolicy: ClusterFirst
    nodeName: gke-tesg1-default-pool-ff7a1295-nvv4
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: default-token-kchbk
      secret:
        defaultMode: 420
        secretName: default-token-kchbk
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2019-08-31T01:51:55Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2019-08-31T01:51:57Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2019-08-31T01:51:57Z
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: 2019-08-31T01:51:55Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://ac2f5655f23f5863380b33c8fbeb3f11e3f14cacaa428805c542cdb4b4175849
      image: gcr.io/google_samples/gb-redisslave:v1
      imageID: docker-pullable://gcr.io/google_samples/gb-redisslave@sha256:90f62695e641e1a27d1a5e0bbb8b622205a48e18311b51b0da419ffad24b9016
      lastState: {}
      name: slave
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2019-08-31T01:51:57Z
    hostIP: 10.128.0.15
    phase: Running
    podIP: 10.8.2.106
    qosClass: Burstable
    startTime: 2019-08-31T01:51:55Z
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: 2019-06-18T22:22:15Z
    generateName: event-exporter-v0.2.4-5f7d5d7dd4-
    labels:
      k8s-app: event-exporter
      pod-template-hash: 5f7d5d7dd4
      version: v0.2.4
    name: event-exporter-v0.2.4-5f7d5d7dd4-7mfz5
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: event-exporter-v0.2.4-5f7d5d7dd4
      uid: 868e50cc-9217-11e9-a049-42010a8000d3
    resourceVersion: "766"
    selfLink: /api/v1/namespaces/kube-system/pods/event-exporter-v0.2.4-5f7d5d7dd4-7mfz5
    uid: 868f7ab9-9217-11e9-a049-42010a8000d3
  spec:
    containers:
    - command:
      - /event-exporter
      - -sink-opts=-stackdriver-resource-model=old
      image: k8s.gcr.io/event-exporter:v0.2.4
      imagePullPolicy: IfNotPresent
      name: event-exporter
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: event-exporter-sa-token-bnkrr
        readOnly: true
    - command:
      - /monitor
      - --stackdriver-prefix=container.googleapis.com/internal/addons
      - --api-override=https://monitoring.googleapis.com/
      - --source=event_exporter:http://localhost:80?whitelisted=stackdriver_sink_received_entry_count,stackdriver_sink_request_count,stackdriver_sink_successfully_sent_entry_count
      - --pod-id=$(POD_NAME)
      - --namespace-id=$(POD_NAMESPACE)
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: k8s.gcr.io/prometheus-to-sd:v0.5.0
      imagePullPolicy: IfNotPresent
      name: prometheus-to-sd-exporter
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: event-exporter-sa-token-bnkrr
        readOnly: true
    dnsPolicy: ClusterFirst
    nodeName: gke-tesg1-default-pool-ff7a1295-z7lx
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: event-exporter-sa
    serviceAccountName: event-exporter-sa
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - hostPath:
        path: /etc/ssl/certs
        type: ""
      name: ssl-certs
    - name: event-exporter-sa-token-bnkrr
      secret:
        defaultMode: 420
        secretName: event-exporter-sa-token-bnkrr
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:26Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:51Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:51Z
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:26Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://a16d968771a49b28236bf05c103a9f5692560e3b7c69a210b2a38792259c091c
      image: k8s.gcr.io/event-exporter:v0.2.4
      imageID: docker-pullable://k8s.gcr.io/event-exporter@sha256:16ca66e2b5dc7a1ce6a5aafcb21d0885828b75cdfc08135430480f7ad2364adc
      lastState: {}
      name: event-exporter
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2019-06-18T22:22:44Z
    - containerID: docker://89f5b754d796b45fde232a46d1fc9f5908504c442b1a0b31a78ef60c7fbc6f45
      image: k8s.gcr.io/prometheus-to-sd:v0.5.0
      imageID: docker-pullable://k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e
      lastState: {}
      name: prometheus-to-sd-exporter
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2019-06-18T22:22:47Z
    hostIP: 10.128.0.13
    phase: Running
    podIP: 10.8.0.4
    qosClass: BestEffort
    startTime: 2019-06-18T22:22:26Z
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: 2019-06-18T22:22:28Z
    generateName: fluentd-gcp-scaler-7b895cbc89-
    labels:
      k8s-app: fluentd-gcp-scaler
      pod-template-hash: 7b895cbc89
    name: fluentd-gcp-scaler-7b895cbc89-jwx5z
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: fluentd-gcp-scaler-7b895cbc89
      uid: 8e49db2f-9217-11e9-a049-42010a8000d3
    resourceVersion: "594"
    selfLink: /api/v1/namespaces/kube-system/pods/fluentd-gcp-scaler-7b895cbc89-jwx5z
    uid: 8e4ac837-9217-11e9-a049-42010a8000d3
  spec:
    containers:
    - command:
      - /scaler.sh
      - --ds-name=fluentd-gcp-v3.2.0
      - --scaling-policy=fluentd-gcp-scaling-policy
      env:
      - name: CPU_REQUEST
        value: 100m
      - name: MEMORY_REQUEST
        value: 200Mi
      - name: CPU_LIMIT
        value: 1000m
      - name: MEMORY_LIMIT
        value: 500Mi
      image: k8s.gcr.io/fluentd-gcp-scaler:0.5.1
      imagePullPolicy: IfNotPresent
      name: fluentd-gcp-scaler
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: fluentd-gcp-scaler-token-tb8bz
        readOnly: true
    dnsPolicy: ClusterFirst
    nodeName: gke-tesg1-default-pool-ff7a1295-nvv4
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: fluentd-gcp-scaler
    serviceAccountName: fluentd-gcp-scaler
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: fluentd-gcp-scaler-token-tb8bz
      secret:
        defaultMode: 420
        secretName: fluentd-gcp-scaler-token-tb8bz
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:28Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:32Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:32Z
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:28Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://7931dd0b11308d14487406490a24935be5bb8c9df2ef016e0551ca3174bab170
      image: k8s.gcr.io/fluentd-gcp-scaler:0.5.1
      imageID: docker-pullable://k8s.gcr.io/fluentd-gcp-scaler@sha256:a5ace7506d393c4ed65eb2cbb6312c64ab357fcea16dff76b9055bc6e498e5ff
      lastState: {}
      name: fluentd-gcp-scaler
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2019-06-18T22:22:31Z
    hostIP: 10.128.0.15
    phase: Running
    podIP: 10.8.2.2
    qosClass: BestEffort
    startTime: 2019-06-18T22:22:28Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: 2019-06-18T22:22:36Z
    generateName: fluentd-gcp-v3.2.0-
    labels:
      controller-revision-hash: 5f6f57c9d4
      k8s-app: fluentd-gcp
      kubernetes.io/cluster-service: "true"
      pod-template-generation: "2"
      version: v3.2.0
    name: fluentd-gcp-v3.2.0-7kkcj
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: fluentd-gcp-v3.2.0
      uid: 86ae80c3-9217-11e9-a049-42010a8000d3
    resourceVersion: "685"
    selfLink: /api/v1/namespaces/kube-system/pods/fluentd-gcp-v3.2.0-7kkcj
    uid: 938371ba-9217-11e9-a049-42010a8000d3
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - gke-tesg1-default-pool-ff7a1295-7kwg
    containers:
    - env:
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: STACKDRIVER_METADATA_AGENT_URL
        value: http://$(NODE_NAME):8799
      image: gcr.io/stackdriver-agents/stackdriver-logging-agent:0.6-1.6.0-1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        exec:
          command:
          - /bin/sh
          - -c
          - |
            LIVENESS_THRESHOLD_SECONDS=${LIVENESS_THRESHOLD_SECONDS:-300}; STUCK_THRESHOLD_SECONDS=${LIVENESS_THRESHOLD_SECONDS:-900}; if [ ! -e /var/log/fluentd-buffers ]; then
              exit 1;
            fi; touch -d "${STUCK_THRESHOLD_SECONDS} seconds ago" /tmp/marker-stuck; if [[ -z "$(find /var/log/fluentd-buffers -type f -newer /tmp/marker-stuck -print -quit)" ]]; then
              rm -rf /var/log/fluentd-buffers;
              exit 1;
            fi; touch -d "${LIVENESS_THRESHOLD_SECONDS} seconds ago" /tmp/marker-liveness; if [[ -z "$(find /var/log/fluentd-buffers -type f -newer /tmp/marker-liveness -print -quit)" ]]; then
              exit 1;
            fi;
        failureThreshold: 3
        initialDelaySeconds: 600
        periodSeconds: 60
        successThreshold: 1
        timeoutSeconds: 1
      name: fluentd-gcp
      resources:
        limits:
          cpu: "1"
          memory: 500Mi
        requests:
          cpu: 100m
          memory: 200Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/log
        name: varlog
      - mountPath: /var/lib/docker/containers
        name: varlibdockercontainers
        readOnly: true
      - mountPath: /etc/google-fluentd/config.d
        name: config-volume
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: fluentd-gcp-token-vxg67
        readOnly: true
    - command:
      - /monitor
      - --stackdriver-prefix=container.googleapis.com/internal/addons
      - --api-override=https://monitoring.googleapis.com/
      - --source=fluentd:http://localhost:24231?whitelisted=stackdriver_successful_requests_count,stackdriver_failed_requests_count,stackdriver_ingested_entries_count,stackdriver_dropped_entries_count
      - --pod-id=$(POD_NAME)
      - --namespace-id=$(POD_NAMESPACE)
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: k8s.gcr.io/prometheus-to-sd:v0.5.0
      imagePullPolicy: IfNotPresent
      name: prometheus-to-sd-exporter
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: fluentd-gcp-token-vxg67
        readOnly: true
    dnsPolicy: Default
    hostNetwork: true
    nodeName: gke-tesg1-default-pool-ff7a1295-7kwg
    nodeSelector:
      beta.kubernetes.io/fluentd-ds-ready: "true"
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: fluentd-gcp
    serviceAccountName: fluentd-gcp
    terminationGracePeriodSeconds: 60
    tolerations:
    - effect: NoExecute
      operator: Exists
    - effect: NoSchedule
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /var/log
        type: ""
      name: varlog
    - hostPath:
        path: /var/lib/docker/containers
        type: ""
      name: varlibdockercontainers
    - configMap:
        defaultMode: 420
        name: fluentd-gcp-config-old-v1.2.5
      name: config-volume
    - name: fluentd-gcp-token-vxg67
      secret:
        defaultMode: 420
        secretName: fluentd-gcp-token-vxg67
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:36Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:42Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:42Z
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:36Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://47905886e2fa7974986d96e39554a72302596212e23eeb387b2cf41331d7fe7e
      image: gcr.io/stackdriver-agents/stackdriver-logging-agent:0.6-1.6.0-1
      imageID: docker-pullable://gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:f8d5231b67b9c53f60068b535a11811d29d1b3efd53d2b79f2a2591ea338e4f2
      lastState: {}
      name: fluentd-gcp
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2019-06-18T22:22:41Z
    - containerID: docker://8b309a888a97af46fa273f8aad8c9970a99cca848453d571503f475144ab3363
      image: k8s.gcr.io/prometheus-to-sd:v0.5.0
      imageID: docker-pullable://k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e
      lastState: {}
      name: prometheus-to-sd-exporter
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2019-06-18T22:22:42Z
    hostIP: 10.128.0.14
    phase: Running
    podIP: 10.128.0.14
    qosClass: Burstable
    startTime: 2019-06-18T22:22:36Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: 2019-06-18T22:22:36Z
    generateName: fluentd-gcp-v3.2.0-
    labels:
      controller-revision-hash: 5f6f57c9d4
      k8s-app: fluentd-gcp
      kubernetes.io/cluster-service: "true"
      pod-template-generation: "2"
      version: v3.2.0
    name: fluentd-gcp-v3.2.0-9ps5k
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: fluentd-gcp-v3.2.0
      uid: 86ae80c3-9217-11e9-a049-42010a8000d3
    resourceVersion: "678"
    selfLink: /api/v1/namespaces/kube-system/pods/fluentd-gcp-v3.2.0-9ps5k
    uid: 9384932f-9217-11e9-a049-42010a8000d3
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - gke-tesg1-default-pool-ff7a1295-nvv4
    containers:
    - env:
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: STACKDRIVER_METADATA_AGENT_URL
        value: http://$(NODE_NAME):8799
      image: gcr.io/stackdriver-agents/stackdriver-logging-agent:0.6-1.6.0-1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        exec:
          command:
          - /bin/sh
          - -c
          - |
            LIVENESS_THRESHOLD_SECONDS=${LIVENESS_THRESHOLD_SECONDS:-300}; STUCK_THRESHOLD_SECONDS=${LIVENESS_THRESHOLD_SECONDS:-900}; if [ ! -e /var/log/fluentd-buffers ]; then
              exit 1;
            fi; touch -d "${STUCK_THRESHOLD_SECONDS} seconds ago" /tmp/marker-stuck; if [[ -z "$(find /var/log/fluentd-buffers -type f -newer /tmp/marker-stuck -print -quit)" ]]; then
              rm -rf /var/log/fluentd-buffers;
              exit 1;
            fi; touch -d "${LIVENESS_THRESHOLD_SECONDS} seconds ago" /tmp/marker-liveness; if [[ -z "$(find /var/log/fluentd-buffers -type f -newer /tmp/marker-liveness -print -quit)" ]]; then
              exit 1;
            fi;
        failureThreshold: 3
        initialDelaySeconds: 600
        periodSeconds: 60
        successThreshold: 1
        timeoutSeconds: 1
      name: fluentd-gcp
      resources:
        limits:
          cpu: "1"
          memory: 500Mi
        requests:
          cpu: 100m
          memory: 200Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/log
        name: varlog
      - mountPath: /var/lib/docker/containers
        name: varlibdockercontainers
        readOnly: true
      - mountPath: /etc/google-fluentd/config.d
        name: config-volume
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: fluentd-gcp-token-vxg67
        readOnly: true
    - command:
      - /monitor
      - --stackdriver-prefix=container.googleapis.com/internal/addons
      - --api-override=https://monitoring.googleapis.com/
      - --source=fluentd:http://localhost:24231?whitelisted=stackdriver_successful_requests_count,stackdriver_failed_requests_count,stackdriver_ingested_entries_count,stackdriver_dropped_entries_count
      - --pod-id=$(POD_NAME)
      - --namespace-id=$(POD_NAMESPACE)
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: k8s.gcr.io/prometheus-to-sd:v0.5.0
      imagePullPolicy: IfNotPresent
      name: prometheus-to-sd-exporter
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: fluentd-gcp-token-vxg67
        readOnly: true
    dnsPolicy: Default
    hostNetwork: true
    nodeName: gke-tesg1-default-pool-ff7a1295-nvv4
    nodeSelector:
      beta.kubernetes.io/fluentd-ds-ready: "true"
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: fluentd-gcp
    serviceAccountName: fluentd-gcp
    terminationGracePeriodSeconds: 60
    tolerations:
    - effect: NoExecute
      operator: Exists
    - effect: NoSchedule
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /var/log
        type: ""
      name: varlog
    - hostPath:
        path: /var/lib/docker/containers
        type: ""
      name: varlibdockercontainers
    - configMap:
        defaultMode: 420
        name: fluentd-gcp-config-old-v1.2.5
      name: config-volume
    - name: fluentd-gcp-token-vxg67
      secret:
        defaultMode: 420
        secretName: fluentd-gcp-token-vxg67
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:38Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:40Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:40Z
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:36Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://499dc3910f13013a8da8d6f7415d8536ba355b8a064e930d83d5eb668dd81211
      image: gcr.io/stackdriver-agents/stackdriver-logging-agent:0.6-1.6.0-1
      imageID: docker-pullable://gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:f8d5231b67b9c53f60068b535a11811d29d1b3efd53d2b79f2a2591ea338e4f2
      lastState: {}
      name: fluentd-gcp
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2019-06-18T22:22:40Z
    - containerID: docker://7ac209ee9e7c931d023eb465ac680a07bd710a5bac715f7a57ba22015046ac49
      image: k8s.gcr.io/prometheus-to-sd:v0.5.0
      imageID: docker-pullable://k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e
      lastState: {}
      name: prometheus-to-sd-exporter
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2019-06-18T22:22:40Z
    hostIP: 10.128.0.15
    phase: Running
    podIP: 10.128.0.15
    qosClass: Burstable
    startTime: 2019-06-18T22:22:38Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: 2019-08-14T18:17:23Z
    generateName: fluentd-gcp-v3.2.0-
    labels:
      controller-revision-hash: 5f6f57c9d4
      k8s-app: fluentd-gcp
      kubernetes.io/cluster-service: "true"
      pod-template-generation: "2"
      version: v3.2.0
    name: fluentd-gcp-v3.2.0-bfltt
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: fluentd-gcp-v3.2.0
      uid: 86ae80c3-9217-11e9-a049-42010a8000d3
    resourceVersion: "14842904"
    selfLink: /api/v1/namespaces/kube-system/pods/fluentd-gcp-v3.2.0-bfltt
    uid: c3410a7d-bebf-11e9-98f3-42010a8000c4
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - gke-tesg1-default-pool-ff7a1295-zpc5
    containers:
    - env:
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: STACKDRIVER_METADATA_AGENT_URL
        value: http://$(NODE_NAME):8799
      image: gcr.io/stackdriver-agents/stackdriver-logging-agent:0.6-1.6.0-1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        exec:
          command:
          - /bin/sh
          - -c
          - |
            LIVENESS_THRESHOLD_SECONDS=${LIVENESS_THRESHOLD_SECONDS:-300}; STUCK_THRESHOLD_SECONDS=${LIVENESS_THRESHOLD_SECONDS:-900}; if [ ! -e /var/log/fluentd-buffers ]; then
              exit 1;
            fi; touch -d "${STUCK_THRESHOLD_SECONDS} seconds ago" /tmp/marker-stuck; if [[ -z "$(find /var/log/fluentd-buffers -type f -newer /tmp/marker-stuck -print -quit)" ]]; then
              rm -rf /var/log/fluentd-buffers;
              exit 1;
            fi; touch -d "${LIVENESS_THRESHOLD_SECONDS} seconds ago" /tmp/marker-liveness; if [[ -z "$(find /var/log/fluentd-buffers -type f -newer /tmp/marker-liveness -print -quit)" ]]; then
              exit 1;
            fi;
        failureThreshold: 3
        initialDelaySeconds: 600
        periodSeconds: 60
        successThreshold: 1
        timeoutSeconds: 1
      name: fluentd-gcp
      resources:
        limits:
          cpu: "1"
          memory: 500Mi
        requests:
          cpu: 100m
          memory: 200Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/log
        name: varlog
      - mountPath: /var/lib/docker/containers
        name: varlibdockercontainers
        readOnly: true
      - mountPath: /etc/google-fluentd/config.d
        name: config-volume
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: fluentd-gcp-token-vxg67
        readOnly: true
    - command:
      - /monitor
      - --stackdriver-prefix=container.googleapis.com/internal/addons
      - --api-override=https://monitoring.googleapis.com/
      - --source=fluentd:http://localhost:24231?whitelisted=stackdriver_successful_requests_count,stackdriver_failed_requests_count,stackdriver_ingested_entries_count,stackdriver_dropped_entries_count
      - --pod-id=$(POD_NAME)
      - --namespace-id=$(POD_NAMESPACE)
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: k8s.gcr.io/prometheus-to-sd:v0.5.0
      imagePullPolicy: IfNotPresent
      name: prometheus-to-sd-exporter
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: fluentd-gcp-token-vxg67
        readOnly: true
    dnsPolicy: Default
    hostNetwork: true
    nodeName: gke-tesg1-default-pool-ff7a1295-zpc5
    nodeSelector:
      beta.kubernetes.io/fluentd-ds-ready: "true"
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: fluentd-gcp
    serviceAccountName: fluentd-gcp
    terminationGracePeriodSeconds: 60
    tolerations:
    - effect: NoExecute
      operator: Exists
    - effect: NoSchedule
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /var/log
        type: ""
      name: varlog
    - hostPath:
        path: /var/lib/docker/containers
        type: ""
      name: varlibdockercontainers
    - configMap:
        defaultMode: 420
        name: fluentd-gcp-config-old-v1.2.5
      name: config-volume
    - name: fluentd-gcp-token-vxg67
      secret:
        defaultMode: 420
        secretName: fluentd-gcp-token-vxg67
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2019-08-14T18:17:23Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2019-08-14T18:17:35Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2019-08-14T18:17:35Z
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: 2019-08-14T18:17:23Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://2a6c03139624110b2f46521db120ea546b80f4d7bf452c278c35f1086ec89179
      image: gcr.io/stackdriver-agents/stackdriver-logging-agent:0.6-1.6.0-1
      imageID: docker-pullable://gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:f8d5231b67b9c53f60068b535a11811d29d1b3efd53d2b79f2a2591ea338e4f2
      lastState: {}
      name: fluentd-gcp
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2019-08-14T18:17:35Z
    - containerID: docker://ff6652ad48d6d10933b54e2591c67557f3fb1cbb87358d38ce0afa89b7c18b3a
      image: k8s.gcr.io/prometheus-to-sd:v0.5.0
      imageID: docker-pullable://k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e
      lastState: {}
      name: prometheus-to-sd-exporter
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2019-08-14T18:17:35Z
    hostIP: 10.128.0.16
    phase: Running
    podIP: 10.128.0.16
    qosClass: Burstable
    startTime: 2019-08-14T18:17:23Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: 2019-06-18T22:22:36Z
    generateName: fluentd-gcp-v3.2.0-
    labels:
      controller-revision-hash: 5f6f57c9d4
      k8s-app: fluentd-gcp
      kubernetes.io/cluster-service: "true"
      pod-template-generation: "2"
      version: v3.2.0
    name: fluentd-gcp-v3.2.0-fn449
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: fluentd-gcp-v3.2.0
      uid: 86ae80c3-9217-11e9-a049-42010a8000d3
    resourceVersion: "659"
    selfLink: /api/v1/namespaces/kube-system/pods/fluentd-gcp-v3.2.0-fn449
    uid: 9385189d-9217-11e9-a049-42010a8000d3
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - gke-tesg1-default-pool-ff7a1295-z7lx
    containers:
    - env:
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: STACKDRIVER_METADATA_AGENT_URL
        value: http://$(NODE_NAME):8799
      image: gcr.io/stackdriver-agents/stackdriver-logging-agent:0.6-1.6.0-1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        exec:
          command:
          - /bin/sh
          - -c
          - |
            LIVENESS_THRESHOLD_SECONDS=${LIVENESS_THRESHOLD_SECONDS:-300}; STUCK_THRESHOLD_SECONDS=${LIVENESS_THRESHOLD_SECONDS:-900}; if [ ! -e /var/log/fluentd-buffers ]; then
              exit 1;
            fi; touch -d "${STUCK_THRESHOLD_SECONDS} seconds ago" /tmp/marker-stuck; if [[ -z "$(find /var/log/fluentd-buffers -type f -newer /tmp/marker-stuck -print -quit)" ]]; then
              rm -rf /var/log/fluentd-buffers;
              exit 1;
            fi; touch -d "${LIVENESS_THRESHOLD_SECONDS} seconds ago" /tmp/marker-liveness; if [[ -z "$(find /var/log/fluentd-buffers -type f -newer /tmp/marker-liveness -print -quit)" ]]; then
              exit 1;
            fi;
        failureThreshold: 3
        initialDelaySeconds: 600
        periodSeconds: 60
        successThreshold: 1
        timeoutSeconds: 1
      name: fluentd-gcp
      resources:
        limits:
          cpu: "1"
          memory: 500Mi
        requests:
          cpu: 100m
          memory: 200Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/log
        name: varlog
      - mountPath: /var/lib/docker/containers
        name: varlibdockercontainers
        readOnly: true
      - mountPath: /etc/google-fluentd/config.d
        name: config-volume
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: fluentd-gcp-token-vxg67
        readOnly: true
    - command:
      - /monitor
      - --stackdriver-prefix=container.googleapis.com/internal/addons
      - --api-override=https://monitoring.googleapis.com/
      - --source=fluentd:http://localhost:24231?whitelisted=stackdriver_successful_requests_count,stackdriver_failed_requests_count,stackdriver_ingested_entries_count,stackdriver_dropped_entries_count
      - --pod-id=$(POD_NAME)
      - --namespace-id=$(POD_NAMESPACE)
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: k8s.gcr.io/prometheus-to-sd:v0.5.0
      imagePullPolicy: IfNotPresent
      name: prometheus-to-sd-exporter
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: fluentd-gcp-token-vxg67
        readOnly: true
    dnsPolicy: Default
    hostNetwork: true
    nodeName: gke-tesg1-default-pool-ff7a1295-z7lx
    nodeSelector:
      beta.kubernetes.io/fluentd-ds-ready: "true"
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: fluentd-gcp
    serviceAccountName: fluentd-gcp
    terminationGracePeriodSeconds: 60
    tolerations:
    - effect: NoExecute
      operator: Exists
    - effect: NoSchedule
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /var/log
        type: ""
      name: varlog
    - hostPath:
        path: /var/lib/docker/containers
        type: ""
      name: varlibdockercontainers
    - configMap:
        defaultMode: 420
        name: fluentd-gcp-config-old-v1.2.5
      name: config-volume
    - name: fluentd-gcp-token-vxg67
      secret:
        defaultMode: 420
        secretName: fluentd-gcp-token-vxg67
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:36Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:39Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:39Z
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:36Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://b9a7d275c74ccc33b80c2ed141aead286e7f7bfd2887e545af60bd1630ca8b4e
      image: gcr.io/stackdriver-agents/stackdriver-logging-agent:0.6-1.6.0-1
      imageID: docker-pullable://gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:f8d5231b67b9c53f60068b535a11811d29d1b3efd53d2b79f2a2591ea338e4f2
      lastState: {}
      name: fluentd-gcp
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2019-06-18T22:22:38Z
    - containerID: docker://a1c87e173bc11f1daf4466689c25d847e7561c5d388b2852d40994b31b2e6b28
      image: k8s.gcr.io/prometheus-to-sd:v0.5.0
      imageID: docker-pullable://k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e
      lastState: {}
      name: prometheus-to-sd-exporter
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2019-06-18T22:22:39Z
    hostIP: 10.128.0.13
    phase: Running
    podIP: 10.128.0.13
    qosClass: Burstable
    startTime: 2019-06-18T22:22:36Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: 2019-08-14T20:40:52Z
    generateName: fluentd-gcp-v3.2.0-
    labels:
      controller-revision-hash: 5f6f57c9d4
      k8s-app: fluentd-gcp
      kubernetes.io/cluster-service: "true"
      pod-template-generation: "2"
      version: v3.2.0
    name: fluentd-gcp-v3.2.0-lpchk
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: fluentd-gcp-v3.2.0
      uid: 86ae80c3-9217-11e9-a049-42010a8000d3
    resourceVersion: "14870554"
    selfLink: /api/v1/namespaces/kube-system/pods/fluentd-gcp-v3.2.0-lpchk
    uid: ce721a38-bed3-11e9-98f3-42010a8000c4
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - gke-tesg1-default-pool-ff7a1295-dmtd
    containers:
    - env:
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: STACKDRIVER_METADATA_AGENT_URL
        value: http://$(NODE_NAME):8799
      image: gcr.io/stackdriver-agents/stackdriver-logging-agent:0.6-1.6.0-1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        exec:
          command:
          - /bin/sh
          - -c
          - |
            LIVENESS_THRESHOLD_SECONDS=${LIVENESS_THRESHOLD_SECONDS:-300}; STUCK_THRESHOLD_SECONDS=${LIVENESS_THRESHOLD_SECONDS:-900}; if [ ! -e /var/log/fluentd-buffers ]; then
              exit 1;
            fi; touch -d "${STUCK_THRESHOLD_SECONDS} seconds ago" /tmp/marker-stuck; if [[ -z "$(find /var/log/fluentd-buffers -type f -newer /tmp/marker-stuck -print -quit)" ]]; then
              rm -rf /var/log/fluentd-buffers;
              exit 1;
            fi; touch -d "${LIVENESS_THRESHOLD_SECONDS} seconds ago" /tmp/marker-liveness; if [[ -z "$(find /var/log/fluentd-buffers -type f -newer /tmp/marker-liveness -print -quit)" ]]; then
              exit 1;
            fi;
        failureThreshold: 3
        initialDelaySeconds: 600
        periodSeconds: 60
        successThreshold: 1
        timeoutSeconds: 1
      name: fluentd-gcp
      resources:
        limits:
          cpu: "1"
          memory: 500Mi
        requests:
          cpu: 100m
          memory: 200Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/log
        name: varlog
      - mountPath: /var/lib/docker/containers
        name: varlibdockercontainers
        readOnly: true
      - mountPath: /etc/google-fluentd/config.d
        name: config-volume
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: fluentd-gcp-token-vxg67
        readOnly: true
    - command:
      - /monitor
      - --stackdriver-prefix=container.googleapis.com/internal/addons
      - --api-override=https://monitoring.googleapis.com/
      - --source=fluentd:http://localhost:24231?whitelisted=stackdriver_successful_requests_count,stackdriver_failed_requests_count,stackdriver_ingested_entries_count,stackdriver_dropped_entries_count
      - --pod-id=$(POD_NAME)
      - --namespace-id=$(POD_NAMESPACE)
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: k8s.gcr.io/prometheus-to-sd:v0.5.0
      imagePullPolicy: IfNotPresent
      name: prometheus-to-sd-exporter
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: fluentd-gcp-token-vxg67
        readOnly: true
    dnsPolicy: Default
    hostNetwork: true
    nodeName: gke-tesg1-default-pool-ff7a1295-dmtd
    nodeSelector:
      beta.kubernetes.io/fluentd-ds-ready: "true"
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: fluentd-gcp
    serviceAccountName: fluentd-gcp
    terminationGracePeriodSeconds: 60
    tolerations:
    - effect: NoExecute
      operator: Exists
    - effect: NoSchedule
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /var/log
        type: ""
      name: varlog
    - hostPath:
        path: /var/lib/docker/containers
        type: ""
      name: varlibdockercontainers
    - configMap:
        defaultMode: 420
        name: fluentd-gcp-config-old-v1.2.5
      name: config-volume
    - name: fluentd-gcp-token-vxg67
      secret:
        defaultMode: 420
        secretName: fluentd-gcp-token-vxg67
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2019-08-14T20:40:52Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2019-08-14T20:41:07Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2019-08-14T20:41:07Z
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: 2019-08-14T20:40:52Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://ed45ef00ca6c83344d23fef50f86f9473435204365a71b4410a466d0754bb905
      image: gcr.io/stackdriver-agents/stackdriver-logging-agent:0.6-1.6.0-1
      imageID: docker-pullable://gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:f8d5231b67b9c53f60068b535a11811d29d1b3efd53d2b79f2a2591ea338e4f2
      lastState: {}
      name: fluentd-gcp
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2019-08-14T20:41:05Z
    - containerID: docker://e7d2d2f23c13d0177408d165f52e792541787c0cb7616450df9188a0edb8f019
      image: k8s.gcr.io/prometheus-to-sd:v0.5.0
      imageID: docker-pullable://k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e
      lastState: {}
      name: prometheus-to-sd-exporter
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2019-08-14T20:41:06Z
    hostIP: 10.128.0.17
    phase: Running
    podIP: 10.128.0.17
    qosClass: Burstable
    startTime: 2019-08-14T20:40:52Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      scheduler.alpha.kubernetes.io/critical-pod: ""
      seccomp.security.alpha.kubernetes.io/pod: docker/default
    creationTimestamp: 2019-06-18T22:22:47Z
    generateName: heapster-v1.6.0-beta.1-68cdfd6769-
    labels:
      k8s-app: heapster
      pod-template-hash: 68cdfd6769
      version: v1.6.0-beta.1
    name: heapster-v1.6.0-beta.1-68cdfd6769-jlmfs
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: heapster-v1.6.0-beta.1-68cdfd6769
      uid: 99cfbb83-9217-11e9-a049-42010a8000d3
    resourceVersion: "759"
    selfLink: /api/v1/namespaces/kube-system/pods/heapster-v1.6.0-beta.1-68cdfd6769-jlmfs
    uid: 99d69b3a-9217-11e9-a049-42010a8000d3
  spec:
    containers:
    - command:
      - /heapster
      - --source=kubernetes.summary_api:?host_id_annotation=container.googleapis.com/instance_id
      - --sink=stackdriver:?cluster_name=tesg1&use_old_resources=true&use_new_resources=false&min_interval_sec=100&batch_export_timeout_sec=110&cluster_location=us-central1-a
      image: k8s.gcr.io/heapster-amd64:v1.6.0-beta.1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: 8082
          scheme: HTTP
        initialDelaySeconds: 180
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: heapster
      resources:
        limits:
          cpu: 13m
          memory: 120Mi
        requests:
          cpu: 13m
          memory: 120Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: heapster-token-jx6jf
        readOnly: true
    - command:
      - /monitor
      - --source=heapster:http://localhost:8082?whitelisted=stackdriver_requests_count,stackdriver_timeseries_count
      - --stackdriver-prefix=container.googleapis.com/internal/addons
      - --api-override=https://monitoring.googleapis.com/
      - --pod-id=$(POD_NAME)
      - --namespace-id=$(POD_NAMESPACE)
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: k8s.gcr.io/prometheus-to-sd:v0.5.0
      imagePullPolicy: IfNotPresent
      name: prom-to-sd
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: heapster-token-jx6jf
        readOnly: true
    - command:
      - /pod_nanny
      - --config-dir=/etc/config
      - --cpu=10m
      - --extra-cpu=0.5m
      - --memory=100Mi
      - --extra-memory=4Mi
      - --threshold=5
      - --deployment=heapster-v1.6.0-beta.1
      - --container=heapster
      - --poll-period=300000
      - --estimator=exponential
      - --minClusterSize=5
      env:
      - name: MY_POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: MY_POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: k8s.gcr.io/addon-resizer:1.8.3
      imagePullPolicy: IfNotPresent
      name: heapster-nanny
      resources:
        limits:
          cpu: 50m
          memory: 92960Ki
        requests:
          cpu: 50m
          memory: 92960Ki
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/config
        name: heapster-config-volume
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: heapster-token-jx6jf
        readOnly: true
    dnsPolicy: ClusterFirst
    nodeName: gke-tesg1-default-pool-ff7a1295-nvv4
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: heapster
    serviceAccountName: heapster
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: heapster-config
      name: heapster-config-volume
    - name: heapster-token-jx6jf
      secret:
        defaultMode: 420
        secretName: heapster-token-jx6jf
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:47Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:52Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:52Z
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:47Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://3aef2e789fe3f521f79bb81fc1b15f7ad0940026ffa20c41b2b3aa64c8d28a7f
      image: k8s.gcr.io/heapster-amd64:v1.6.0-beta.1
      imageID: docker-pullable://k8s.gcr.io/heapster-amd64@sha256:9fae0af136ce0cf4f88393b3670f7139ffc464692060c374d2ae748e13144521
      lastState: {}
      name: heapster
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2019-06-18T22:22:51Z
    - containerID: docker://502e64c6c6e0504fe9facf3ab48bdb2d6f75233f1e754c28ed306d09c86fa76d
      image: k8s.gcr.io/addon-resizer:1.8.3
      imageID: docker-pullable://k8s.gcr.io/addon-resizer@sha256:07353f7b26327f0d933515a22b1de587b040d3d85c464ea299c1b9f242529326
      lastState: {}
      name: heapster-nanny
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2019-06-18T22:22:52Z
    - containerID: docker://52abaaf1d074315ad5323417fa3bb13d1f7a2b9ac6eb4e0a91b1150f63258878
      image: k8s.gcr.io/prometheus-to-sd:v0.5.0
      imageID: docker-pullable://k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e
      lastState: {}
      name: prom-to-sd
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2019-06-18T22:22:51Z
    hostIP: 10.128.0.15
    phase: Running
    podIP: 10.8.2.3
    qosClass: Burstable
    startTime: 2019-06-18T22:22:47Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      scheduler.alpha.kubernetes.io/critical-pod: ""
      seccomp.security.alpha.kubernetes.io/pod: docker/default
    creationTimestamp: 2019-06-18T22:22:36Z
    generateName: kube-dns-autoscaler-76fcd5f658-
    labels:
      k8s-app: kube-dns-autoscaler
      pod-template-hash: 76fcd5f658
    name: kube-dns-autoscaler-76fcd5f658-rnlsr
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: kube-dns-autoscaler-76fcd5f658
      uid: 865eb933-9217-11e9-a049-42010a8000d3
    resourceVersion: "662"
    selfLink: /api/v1/namespaces/kube-system/pods/kube-dns-autoscaler-76fcd5f658-rnlsr
    uid: 931e934b-9217-11e9-a049-42010a8000d3
  spec:
    containers:
    - command:
      - /cluster-proportional-autoscaler
      - --namespace=kube-system
      - --configmap=kube-dns-autoscaler
      - --target=Deployment/kube-dns
      - --default-params={"linear":{"coresPerReplica":256,"nodesPerReplica":16,"preventSinglePointFailure":true}}
      - --logtostderr=true
      - --v=2
      image: k8s.gcr.io/cluster-proportional-autoscaler-amd64:1.2.0
      imagePullPolicy: IfNotPresent
      name: autoscaler
      resources:
        requests:
          cpu: 20m
          memory: 10Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-dns-autoscaler-token-pk8rd
        readOnly: true
    dnsPolicy: ClusterFirst
    nodeName: gke-tesg1-default-pool-ff7a1295-7kwg
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kube-dns-autoscaler
    serviceAccountName: kube-dns-autoscaler
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-dns-autoscaler-token-pk8rd
      secret:
        defaultMode: 420
        secretName: kube-dns-autoscaler-token-pk8rd
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:36Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:40Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:40Z
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:36Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://49ed462fc1735138f8d68eda8f2c790c506ef26098acb86af6b0629e2af6b40c
      image: k8s.gcr.io/cluster-proportional-autoscaler-amd64:1.2.0
      imageID: docker-pullable://k8s.gcr.io/cluster-proportional-autoscaler-amd64@sha256:36359630278b119e7dd78f5437be1c667080108fa59ecba1b81cda3610dcf4d7
      lastState: {}
      name: autoscaler
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2019-06-18T22:22:39Z
    hostIP: 10.128.0.14
    phase: Running
    podIP: 10.8.1.2
    qosClass: Burstable
    startTime: 2019-06-18T22:22:36Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      scheduler.alpha.kubernetes.io/critical-pod: ""
      seccomp.security.alpha.kubernetes.io/pod: docker/default
    creationTimestamp: 2019-06-18T22:22:40Z
    generateName: kube-dns-b46cc9485-
    labels:
      k8s-app: kube-dns
      pod-template-hash: b46cc9485
    name: kube-dns-b46cc9485-4zk7g
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: kube-dns-b46cc9485
      uid: 8649f3ba-9217-11e9-a049-42010a8000d3
    resourceVersion: "738"
    selfLink: /api/v1/namespaces/kube-system/pods/kube-dns-b46cc9485-4zk7g
    uid: 95a827c4-9217-11e9-a049-42010a8000d3
  spec:
    containers:
    - args:
      - --domain=cluster.local.
      - --dns-port=10053
      - --config-dir=/kube-dns-config
      - --v=2
      env:
      - name: PROMETHEUS_PORT
        value: "10055"
      image: k8s.gcr.io/k8s-dns-kube-dns-amd64:1.14.13
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /healthcheck/kubedns
          port: 10054
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: kubedns
      ports:
      - containerPort: 10053
        name: dns-local
        protocol: UDP
      - containerPort: 10053
        name: dns-tcp-local
        protocol: TCP
      - containerPort: 10055
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /readiness
          port: 8081
          scheme: HTTP
        initialDelaySeconds: 3
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      resources:
        limits:
          memory: 170Mi
        requests:
          cpu: 100m
          memory: 70Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /kube-dns-config
        name: kube-dns-config
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-dns-token-cnjsm
        readOnly: true
    - args:
      - -v=2
      - -logtostderr
      - -configDir=/etc/k8s/dns/dnsmasq-nanny
      - -restartDnsmasq=true
      - --
      - -k
      - --cache-size=1000
      - --no-negcache
      - --log-facility=-
      - --server=/cluster.local/127.0.0.1#10053
      - --server=/in-addr.arpa/127.0.0.1#10053
      - --server=/ip6.arpa/127.0.0.1#10053
      image: k8s.gcr.io/k8s-dns-dnsmasq-nanny-amd64:1.14.13
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /healthcheck/dnsmasq
          port: 10054
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: dnsmasq
      ports:
      - containerPort: 53
        name: dns
        protocol: UDP
      - containerPort: 53
        name: dns-tcp
        protocol: TCP
      resources:
        requests:
          cpu: 150m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/k8s/dns/dnsmasq-nanny
        name: kube-dns-config
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-dns-token-cnjsm
        readOnly: true
    - args:
      - --v=2
      - --logtostderr
      - --probe=kubedns,127.0.0.1:10053,kubernetes.default.svc.cluster.local,5,SRV
      - --probe=dnsmasq,127.0.0.1:53,kubernetes.default.svc.cluster.local,5,SRV
      image: k8s.gcr.io/k8s-dns-sidecar-amd64:1.14.13
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /metrics
          port: 10054
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: sidecar
      ports:
      - containerPort: 10054
        name: metrics
        protocol: TCP
      resources:
        requests:
          cpu: 10m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-dns-token-cnjsm
        readOnly: true
    - command:
      - /monitor
      - --source=kubedns:http://localhost:10054?whitelisted=probe_kubedns_latency_ms,probe_kubedns_errors,dnsmasq_misses,dnsmasq_hits
      - --stackdriver-prefix=container.googleapis.com/internal/addons
      - --api-override=https://monitoring.googleapis.com/
      - --pod-id=$(POD_NAME)
      - --namespace-id=$(POD_NAMESPACE)
      - --v=2
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: k8s.gcr.io/prometheus-to-sd:v0.4.2
      imagePullPolicy: IfNotPresent
      name: prometheus-to-sd
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-dns-token-cnjsm
        readOnly: true
    dnsPolicy: Default
    nodeName: gke-tesg1-default-pool-ff7a1295-7kwg
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kube-dns
    serviceAccountName: kube-dns
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: kube-dns
        optional: true
      name: kube-dns-config
    - name: kube-dns-token-cnjsm
      secret:
        defaultMode: 420
        secretName: kube-dns-token-cnjsm
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:40Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:48Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:48Z
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:40Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://ea2eb77a3de5720f4486cfa65a3abd0e153970c2dc29cc2e5f802af11319021c
      image: k8s.gcr.io/k8s-dns-dnsmasq-nanny-amd64:1.14.13
      imageID: docker-pullable://k8s.gcr.io/k8s-dns-dnsmasq-nanny-amd64@sha256:45df3e8e0c551bd0c79cdba48ae6677f817971dcbd1eeed7fd1f9a35118410e4
      lastState: {}
      name: dnsmasq
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2019-06-18T22:22:42Z
    - containerID: docker://294d5827243fcf5b5007f224121633336f0449cdb6d8142a587a978586252c07
      image: k8s.gcr.io/k8s-dns-kube-dns-amd64:1.14.13
      imageID: docker-pullable://k8s.gcr.io/k8s-dns-kube-dns-amd64@sha256:618a82fa66cf0c75e4753369a6999032372be7308866fc9afb381789b1e5ad52
      lastState: {}
      name: kubedns
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2019-06-18T22:22:42Z
    - containerID: docker://09c71662aa28d65f42a18e8198b2871faa90ccdc80e20505d09d5117c067533f
      image: k8s.gcr.io/prometheus-to-sd:v0.4.2
      imageID: docker-pullable://k8s.gcr.io/prometheus-to-sd@sha256:aca8ef83a7fae83f1f8583e978dd4d1ff655b9f2ca0a76bda5edce6d8965bdf2
      lastState: {}
      name: prometheus-to-sd
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2019-06-18T22:22:45Z
    - containerID: docker://451af171b973533d86dbcd5cacc7303a4b42107484516e4110b6a4cc0d494150
      image: k8s.gcr.io/k8s-dns-sidecar-amd64:1.14.13
      imageID: docker-pullable://k8s.gcr.io/k8s-dns-sidecar-amd64@sha256:cedc8fe2098dffc26d17f64061296b7aa54258a31513b6c52df271a98bb522b3
      lastState: {}
      name: sidecar
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2019-06-18T22:22:43Z
    hostIP: 10.128.0.14
    phase: Running
    podIP: 10.8.1.3
    qosClass: Burstable
    startTime: 2019-06-18T22:22:40Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      scheduler.alpha.kubernetes.io/critical-pod: ""
      seccomp.security.alpha.kubernetes.io/pod: docker/default
    creationTimestamp: 2019-06-18T22:22:14Z
    generateName: kube-dns-b46cc9485-
    labels:
      k8s-app: kube-dns
      pod-template-hash: b46cc9485
    name: kube-dns-b46cc9485-9nfcn
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: kube-dns-b46cc9485
      uid: 8649f3ba-9217-11e9-a049-42010a8000d3
    resourceVersion: "805"
    selfLink: /api/v1/namespaces/kube-system/pods/kube-dns-b46cc9485-9nfcn
    uid: 864c17a5-9217-11e9-a049-42010a8000d3
  spec:
    containers:
    - args:
      - --domain=cluster.local.
      - --dns-port=10053
      - --config-dir=/kube-dns-config
      - --v=2
      env:
      - name: PROMETHEUS_PORT
        value: "10055"
      image: k8s.gcr.io/k8s-dns-kube-dns-amd64:1.14.13
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /healthcheck/kubedns
          port: 10054
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: kubedns
      ports:
      - containerPort: 10053
        name: dns-local
        protocol: UDP
      - containerPort: 10053
        name: dns-tcp-local
        protocol: TCP
      - containerPort: 10055
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /readiness
          port: 8081
          scheme: HTTP
        initialDelaySeconds: 3
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      resources:
        limits:
          memory: 170Mi
        requests:
          cpu: 100m
          memory: 70Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /kube-dns-config
        name: kube-dns-config
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-dns-token-cnjsm
        readOnly: true
    - args:
      - -v=2
      - -logtostderr
      - -configDir=/etc/k8s/dns/dnsmasq-nanny
      - -restartDnsmasq=true
      - --
      - -k
      - --cache-size=1000
      - --no-negcache
      - --log-facility=-
      - --server=/cluster.local/127.0.0.1#10053
      - --server=/in-addr.arpa/127.0.0.1#10053
      - --server=/ip6.arpa/127.0.0.1#10053
      image: k8s.gcr.io/k8s-dns-dnsmasq-nanny-amd64:1.14.13
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /healthcheck/dnsmasq
          port: 10054
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: dnsmasq
      ports:
      - containerPort: 53
        name: dns
        protocol: UDP
      - containerPort: 53
        name: dns-tcp
        protocol: TCP
      resources:
        requests:
          cpu: 150m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/k8s/dns/dnsmasq-nanny
        name: kube-dns-config
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-dns-token-cnjsm
        readOnly: true
    - args:
      - --v=2
      - --logtostderr
      - --probe=kubedns,127.0.0.1:10053,kubernetes.default.svc.cluster.local,5,SRV
      - --probe=dnsmasq,127.0.0.1:53,kubernetes.default.svc.cluster.local,5,SRV
      image: k8s.gcr.io/k8s-dns-sidecar-amd64:1.14.13
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /metrics
          port: 10054
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: sidecar
      ports:
      - containerPort: 10054
        name: metrics
        protocol: TCP
      resources:
        requests:
          cpu: 10m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-dns-token-cnjsm
        readOnly: true
    - command:
      - /monitor
      - --source=kubedns:http://localhost:10054?whitelisted=probe_kubedns_latency_ms,probe_kubedns_errors,dnsmasq_misses,dnsmasq_hits
      - --stackdriver-prefix=container.googleapis.com/internal/addons
      - --api-override=https://monitoring.googleapis.com/
      - --pod-id=$(POD_NAME)
      - --namespace-id=$(POD_NAMESPACE)
      - --v=2
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: k8s.gcr.io/prometheus-to-sd:v0.4.2
      imagePullPolicy: IfNotPresent
      name: prometheus-to-sd
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-dns-token-cnjsm
        readOnly: true
    dnsPolicy: Default
    nodeName: gke-tesg1-default-pool-ff7a1295-z7lx
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kube-dns
    serviceAccountName: kube-dns
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: kube-dns
        optional: true
      name: kube-dns-config
    - name: kube-dns-token-cnjsm
      secret:
        defaultMode: 420
        secretName: kube-dns-token-cnjsm
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:26Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:23:02Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:23:02Z
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:26Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://56db023287d8991e327a1f3faf853b78ba0f829972b469511d01e2f418151b03
      image: k8s.gcr.io/k8s-dns-dnsmasq-nanny-amd64:1.14.13
      imageID: docker-pullable://k8s.gcr.io/k8s-dns-dnsmasq-nanny-amd64@sha256:45df3e8e0c551bd0c79cdba48ae6677f817971dcbd1eeed7fd1f9a35118410e4
      lastState: {}
      name: dnsmasq
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2019-06-18T22:22:51Z
    - containerID: docker://5d827a1295978a037788891b0b55a9721f612dda00854b2ca542672ab8f02326
      image: k8s.gcr.io/k8s-dns-kube-dns-amd64:1.14.13
      imageID: docker-pullable://k8s.gcr.io/k8s-dns-kube-dns-amd64@sha256:618a82fa66cf0c75e4753369a6999032372be7308866fc9afb381789b1e5ad52
      lastState: {}
      name: kubedns
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2019-06-18T22:22:51Z
    - containerID: docker://5714e98bfd1abb29f5c4c1de0eefeb47802421ce2503763de0bc76c611091921
      image: k8s.gcr.io/prometheus-to-sd:v0.4.2
      imageID: docker-pullable://k8s.gcr.io/prometheus-to-sd@sha256:aca8ef83a7fae83f1f8583e978dd4d1ff655b9f2ca0a76bda5edce6d8965bdf2
      lastState: {}
      name: prometheus-to-sd
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2019-06-18T22:22:54Z
    - containerID: docker://a66a7b0b9af1cc517834f993eb3c8c122e75c9705bbbe25286d94032d7559c67
      image: k8s.gcr.io/k8s-dns-sidecar-amd64:1.14.13
      imageID: docker-pullable://k8s.gcr.io/k8s-dns-sidecar-amd64@sha256:cedc8fe2098dffc26d17f64061296b7aa54258a31513b6c52df271a98bb522b3
      lastState: {}
      name: sidecar
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2019-06-18T22:22:52Z
    hostIP: 10.128.0.13
    phase: Running
    podIP: 10.8.0.6
    qosClass: Burstable
    startTime: 2019-06-18T22:22:26Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: 55057afd0355181dd59a620b4d1677a3
      kubernetes.io/config.mirror: 55057afd0355181dd59a620b4d1677a3
      kubernetes.io/config.seen: 2019-06-18T22:22:27.732454932Z
      kubernetes.io/config.source: file
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: 2019-06-18T22:22:28Z
    labels:
      component: kube-proxy
      tier: node
    name: kube-proxy-gke-tesg1-default-pool-ff7a1295-7kwg
    namespace: kube-system
    resourceVersion: "589"
    selfLink: /api/v1/namespaces/kube-system/pods/kube-proxy-gke-tesg1-default-pool-ff7a1295-7kwg
    uid: 8e62eec8-9217-11e9-a049-42010a8000d3
  spec:
    containers:
    - command:
      - /bin/sh
      - -c
      - exec kube-proxy --master=https://35.225.186.34 --kubeconfig=/var/lib/kube-proxy/kubeconfig
        --cluster-cidr=10.8.0.0/14 --resource-container="" --oom-score-adj=-998 --v=2
        --feature-gates=DynamicKubeletConfig=false,RotateKubeletServerCertificate=true,ExperimentalCriticalPodAnnotation=true
        --iptables-sync-period=1m --iptables-min-sync-period=10s --ipvs-sync-period=1m
        --ipvs-min-sync-period=10s 1>>/var/log/kube-proxy.log 2>&1
      image: k8s.gcr.io/kube-proxy:v1.12.8-gke.6
      imagePullPolicy: IfNotPresent
      name: kube-proxy
      resources:
        requests:
          cpu: 100m
      securityContext:
        privileged: true
        procMount: Default
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/ssl/certs
        name: etc-ssl-certs
        readOnly: true
      - mountPath: /usr/share/ca-certificates
        name: usr-ca-certs
        readOnly: true
      - mountPath: /var/log
        name: varlog
      - mountPath: /var/lib/kube-proxy/kubeconfig
        name: kubeconfig
      - mountPath: /run/xtables.lock
        name: iptableslock
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    nodeName: gke-tesg1-default-pool-ff7a1295-7kwg
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    - effect: NoSchedule
      operator: Exists
    volumes:
    - hostPath:
        path: /usr/share/ca-certificates
        type: ""
      name: usr-ca-certs
    - hostPath:
        path: /etc/ssl/certs
        type: ""
      name: etc-ssl-certs
    - hostPath:
        path: /var/lib/kube-proxy/kubeconfig
        type: FileOrCreate
      name: kubeconfig
    - hostPath:
        path: /var/log
        type: ""
      name: varlog
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: iptableslock
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:28Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:31Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:31Z
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:28Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://de0258e51a87031070db79a29231186987b10d21e459586631d801895d0de437
      image: gcr.io/google_containers/kube-proxy:v1.12.8-gke.6
      imageID: docker://sha256:c573953cb25819897ecfd504bcfca49d57066d71d26cf8914d8d2a59455ad4a1
      lastState: {}
      name: kube-proxy
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2019-06-18T22:22:29Z
    hostIP: 10.128.0.14
    phase: Running
    podIP: 10.128.0.14
    qosClass: Burstable
    startTime: 2019-06-18T22:22:28Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: 55057afd0355181dd59a620b4d1677a3
      kubernetes.io/config.mirror: 55057afd0355181dd59a620b4d1677a3
      kubernetes.io/config.seen: 2019-08-14T20:40:51.776776148Z
      kubernetes.io/config.source: file
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: 2019-08-14T20:40:52Z
    labels:
      component: kube-proxy
      tier: node
    name: kube-proxy-gke-tesg1-default-pool-ff7a1295-dmtd
    namespace: kube-system
    resourceVersion: "14870513"
    selfLink: /api/v1/namespaces/kube-system/pods/kube-proxy-gke-tesg1-default-pool-ff7a1295-dmtd
    uid: ce78f015-bed3-11e9-98f3-42010a8000c4
  spec:
    containers:
    - command:
      - /bin/sh
      - -c
      - exec kube-proxy --master=https://35.225.186.34 --kubeconfig=/var/lib/kube-proxy/kubeconfig
        --cluster-cidr=10.8.0.0/14 --resource-container="" --oom-score-adj=-998 --v=2
        --feature-gates=DynamicKubeletConfig=false,RotateKubeletServerCertificate=true,ExperimentalCriticalPodAnnotation=true
        --iptables-sync-period=1m --iptables-min-sync-period=10s --ipvs-sync-period=1m
        --ipvs-min-sync-period=10s 1>>/var/log/kube-proxy.log 2>&1
      image: k8s.gcr.io/kube-proxy:v1.12.8-gke.6
      imagePullPolicy: IfNotPresent
      name: kube-proxy
      resources:
        requests:
          cpu: 100m
      securityContext:
        privileged: true
        procMount: Default
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/ssl/certs
        name: etc-ssl-certs
        readOnly: true
      - mountPath: /usr/share/ca-certificates
        name: usr-ca-certs
        readOnly: true
      - mountPath: /var/log
        name: varlog
      - mountPath: /var/lib/kube-proxy/kubeconfig
        name: kubeconfig
      - mountPath: /run/xtables.lock
        name: iptableslock
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    nodeName: gke-tesg1-default-pool-ff7a1295-dmtd
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    - effect: NoSchedule
      operator: Exists
    volumes:
    - hostPath:
        path: /usr/share/ca-certificates
        type: ""
      name: usr-ca-certs
    - hostPath:
        path: /etc/ssl/certs
        type: ""
      name: etc-ssl-certs
    - hostPath:
        path: /var/lib/kube-proxy/kubeconfig
        type: FileOrCreate
      name: kubeconfig
    - hostPath:
        path: /var/log
        type: ""
      name: varlog
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: iptableslock
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2019-08-14T20:40:52Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2019-08-14T20:40:55Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2019-08-14T20:40:55Z
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: 2019-08-14T20:40:52Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://de8db90e135a4136623efaf5b227b2412b089186c374c05d4bb8db58feadaa1f
      image: gcr.io/google_containers/kube-proxy:v1.12.8-gke.6
      imageID: docker://sha256:c573953cb25819897ecfd504bcfca49d57066d71d26cf8914d8d2a59455ad4a1
      lastState: {}
      name: kube-proxy
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2019-08-14T20:40:54Z
    hostIP: 10.128.0.17
    phase: Running
    podIP: 10.128.0.17
    qosClass: Burstable
    startTime: 2019-08-14T20:40:52Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: 55057afd0355181dd59a620b4d1677a3
      kubernetes.io/config.mirror: 55057afd0355181dd59a620b4d1677a3
      kubernetes.io/config.seen: 2019-06-18T22:22:26.302258315Z
      kubernetes.io/config.source: file
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: 2019-06-18T22:22:26Z
    labels:
      component: kube-proxy
      tier: node
    name: kube-proxy-gke-tesg1-default-pool-ff7a1295-nvv4
    namespace: kube-system
    resourceVersion: "551"
    selfLink: /api/v1/namespaces/kube-system/pods/kube-proxy-gke-tesg1-default-pool-ff7a1295-nvv4
    uid: 8d8d6f33-9217-11e9-a049-42010a8000d3
  spec:
    containers:
    - command:
      - /bin/sh
      - -c
      - exec kube-proxy --master=https://35.225.186.34 --kubeconfig=/var/lib/kube-proxy/kubeconfig
        --cluster-cidr=10.8.0.0/14 --resource-container="" --oom-score-adj=-998 --v=2
        --feature-gates=DynamicKubeletConfig=false,RotateKubeletServerCertificate=true,ExperimentalCriticalPodAnnotation=true
        --iptables-sync-period=1m --iptables-min-sync-period=10s --ipvs-sync-period=1m
        --ipvs-min-sync-period=10s 1>>/var/log/kube-proxy.log 2>&1
      image: k8s.gcr.io/kube-proxy:v1.12.8-gke.6
      imagePullPolicy: IfNotPresent
      name: kube-proxy
      resources:
        requests:
          cpu: 100m
      securityContext:
        privileged: true
        procMount: Default
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/ssl/certs
        name: etc-ssl-certs
        readOnly: true
      - mountPath: /usr/share/ca-certificates
        name: usr-ca-certs
        readOnly: true
      - mountPath: /var/log
        name: varlog
      - mountPath: /var/lib/kube-proxy/kubeconfig
        name: kubeconfig
      - mountPath: /run/xtables.lock
        name: iptableslock
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    nodeName: gke-tesg1-default-pool-ff7a1295-nvv4
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    - effect: NoSchedule
      operator: Exists
    volumes:
    - hostPath:
        path: /usr/share/ca-certificates
        type: ""
      name: usr-ca-certs
    - hostPath:
        path: /etc/ssl/certs
        type: ""
      name: etc-ssl-certs
    - hostPath:
        path: /var/lib/kube-proxy/kubeconfig
        type: FileOrCreate
      name: kubeconfig
    - hostPath:
        path: /var/log
        type: ""
      name: varlog
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: iptableslock
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:28Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:28Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:28Z
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:28Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://1cd3d4600c09bb77b43d71b758f6663db0265f1a7fd92536adc407536a85ab32
      image: gcr.io/google_containers/kube-proxy:v1.12.8-gke.6
      imageID: docker://sha256:c573953cb25819897ecfd504bcfca49d57066d71d26cf8914d8d2a59455ad4a1
      lastState: {}
      name: kube-proxy
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2019-06-18T22:22:28Z
    hostIP: 10.128.0.15
    phase: Running
    podIP: 10.128.0.15
    qosClass: Burstable
    startTime: 2019-06-18T22:22:28Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: 55057afd0355181dd59a620b4d1677a3
      kubernetes.io/config.mirror: 55057afd0355181dd59a620b4d1677a3
      kubernetes.io/config.seen: 2019-06-18T22:22:26.249512611Z
      kubernetes.io/config.source: file
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: 2019-06-18T22:22:26Z
    labels:
      component: kube-proxy
      tier: node
    name: kube-proxy-gke-tesg1-default-pool-ff7a1295-z7lx
    namespace: kube-system
    resourceVersion: "590"
    selfLink: /api/v1/namespaces/kube-system/pods/kube-proxy-gke-tesg1-default-pool-ff7a1295-z7lx
    uid: 8d839606-9217-11e9-a049-42010a8000d3
  spec:
    containers:
    - command:
      - /bin/sh
      - -c
      - exec kube-proxy --master=https://35.225.186.34 --kubeconfig=/var/lib/kube-proxy/kubeconfig
        --cluster-cidr=10.8.0.0/14 --resource-container="" --oom-score-adj=-998 --v=2
        --feature-gates=DynamicKubeletConfig=false,RotateKubeletServerCertificate=true,ExperimentalCriticalPodAnnotation=true
        --iptables-sync-period=1m --iptables-min-sync-period=10s --ipvs-sync-period=1m
        --ipvs-min-sync-period=10s 1>>/var/log/kube-proxy.log 2>&1
      image: k8s.gcr.io/kube-proxy:v1.12.8-gke.6
      imagePullPolicy: IfNotPresent
      name: kube-proxy
      resources:
        requests:
          cpu: 100m
      securityContext:
        privileged: true
        procMount: Default
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/ssl/certs
        name: etc-ssl-certs
        readOnly: true
      - mountPath: /usr/share/ca-certificates
        name: usr-ca-certs
        readOnly: true
      - mountPath: /var/log
        name: varlog
      - mountPath: /var/lib/kube-proxy/kubeconfig
        name: kubeconfig
      - mountPath: /run/xtables.lock
        name: iptableslock
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    nodeName: gke-tesg1-default-pool-ff7a1295-z7lx
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    - effect: NoSchedule
      operator: Exists
    volumes:
    - hostPath:
        path: /usr/share/ca-certificates
        type: ""
      name: usr-ca-certs
    - hostPath:
        path: /etc/ssl/certs
        type: ""
      name: etc-ssl-certs
    - hostPath:
        path: /var/lib/kube-proxy/kubeconfig
        type: FileOrCreate
      name: kubeconfig
    - hostPath:
        path: /var/log
        type: ""
      name: varlog
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: iptableslock
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:26Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:28Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:28Z
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:26Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://6909f72514371a2cc96416c2c073e36cffbc5924cc36fa1f2fb396e05f198758
      image: gcr.io/google_containers/kube-proxy:v1.12.8-gke.6
      imageID: docker://sha256:c573953cb25819897ecfd504bcfca49d57066d71d26cf8914d8d2a59455ad4a1
      lastState: {}
      name: kube-proxy
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2019-06-18T22:22:27Z
    hostIP: 10.128.0.13
    phase: Running
    podIP: 10.128.0.13
    qosClass: Burstable
    startTime: 2019-06-18T22:22:26Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: 55057afd0355181dd59a620b4d1677a3
      kubernetes.io/config.mirror: 55057afd0355181dd59a620b4d1677a3
      kubernetes.io/config.seen: 2019-08-14T18:17:23.059098137Z
      kubernetes.io/config.source: file
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: 2019-08-14T18:17:23Z
    labels:
      component: kube-proxy
      tier: node
    name: kube-proxy-gke-tesg1-default-pool-ff7a1295-zpc5
    namespace: kube-system
    resourceVersion: "14842872"
    selfLink: /api/v1/namespaces/kube-system/pods/kube-proxy-gke-tesg1-default-pool-ff7a1295-zpc5
    uid: c34051ce-bebf-11e9-98f3-42010a8000c4
  spec:
    containers:
    - command:
      - /bin/sh
      - -c
      - exec kube-proxy --master=https://35.225.186.34 --kubeconfig=/var/lib/kube-proxy/kubeconfig
        --cluster-cidr=10.8.0.0/14 --resource-container="" --oom-score-adj=-998 --v=2
        --feature-gates=DynamicKubeletConfig=false,RotateKubeletServerCertificate=true,ExperimentalCriticalPodAnnotation=true
        --iptables-sync-period=1m --iptables-min-sync-period=10s --ipvs-sync-period=1m
        --ipvs-min-sync-period=10s 1>>/var/log/kube-proxy.log 2>&1
      image: k8s.gcr.io/kube-proxy:v1.12.8-gke.6
      imagePullPolicy: IfNotPresent
      name: kube-proxy
      resources:
        requests:
          cpu: 100m
      securityContext:
        privileged: true
        procMount: Default
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/ssl/certs
        name: etc-ssl-certs
        readOnly: true
      - mountPath: /usr/share/ca-certificates
        name: usr-ca-certs
        readOnly: true
      - mountPath: /var/log
        name: varlog
      - mountPath: /var/lib/kube-proxy/kubeconfig
        name: kubeconfig
      - mountPath: /run/xtables.lock
        name: iptableslock
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    nodeName: gke-tesg1-default-pool-ff7a1295-zpc5
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    - effect: NoSchedule
      operator: Exists
    volumes:
    - hostPath:
        path: /usr/share/ca-certificates
        type: ""
      name: usr-ca-certs
    - hostPath:
        path: /etc/ssl/certs
        type: ""
      name: etc-ssl-certs
    - hostPath:
        path: /var/lib/kube-proxy/kubeconfig
        type: FileOrCreate
      name: kubeconfig
    - hostPath:
        path: /var/log
        type: ""
      name: varlog
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: iptableslock
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2019-08-14T18:17:23Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2019-08-14T18:17:25Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2019-08-14T18:17:25Z
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: 2019-08-14T18:17:23Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://c299068338607f6d53f4f8badd1eec51c2dcf4ed0099e07e0e13427829ffae71
      image: gcr.io/google_containers/kube-proxy:v1.12.8-gke.6
      imageID: docker://sha256:c573953cb25819897ecfd504bcfca49d57066d71d26cf8914d8d2a59455ad4a1
      lastState: {}
      name: kube-proxy
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2019-08-14T18:17:24Z
    hostIP: 10.128.0.16
    phase: Running
    podIP: 10.128.0.16
    qosClass: Burstable
    startTime: 2019-08-14T18:17:23Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      seccomp.security.alpha.kubernetes.io/pod: docker/default
    creationTimestamp: 2019-06-18T22:22:13Z
    generateName: l7-default-backend-6f8697844f-
    labels:
      k8s-app: glbc
      name: glbc
      pod-template-hash: 6f8697844f
    name: l7-default-backend-6f8697844f-2jxzf
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: l7-default-backend-6f8697844f
      uid: 85b5b6e6-9217-11e9-a049-42010a8000d3
    resourceVersion: "770"
    selfLink: /api/v1/namespaces/kube-system/pods/l7-default-backend-6f8697844f-2jxzf
    uid: 85bba5ca-9217-11e9-a049-42010a8000d3
  spec:
    containers:
    - image: k8s.gcr.io/defaultbackend-amd64:1.5
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 30
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: default-http-backend
      ports:
      - containerPort: 8080
        protocol: TCP
      resources:
        limits:
          cpu: 10m
          memory: 20Mi
        requests:
          cpu: 10m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-pbq62
        readOnly: true
    dnsPolicy: ClusterFirst
    nodeName: gke-tesg1-default-pool-ff7a1295-z7lx
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: default-token-pbq62
      secret:
        defaultMode: 420
        secretName: default-token-pbq62
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:26Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:52Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:52Z
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:26Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://abc5b2891e304c2d40bb5ca915d2d5583a1a03eb145d8e2ac959bb12e8362329
      image: k8s.gcr.io/defaultbackend-amd64:1.5
      imageID: docker-pullable://k8s.gcr.io/defaultbackend-amd64@sha256:4dc5e07c8ca4e23bddb3153737d7b8c556e5fb2f29c4558b7cd6e6df99c512c7
      lastState: {}
      name: default-http-backend
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2019-06-18T22:22:50Z
    hostIP: 10.128.0.13
    phase: Running
    podIP: 10.8.0.5
    qosClass: Guaranteed
    startTime: 2019-06-18T22:22:26Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      scheduler.alpha.kubernetes.io/critical-pod: ""
      seccomp.security.alpha.kubernetes.io/pod: docker/default
    creationTimestamp: 2019-06-18T22:22:47Z
    generateName: metrics-server-v0.3.1-5b4d6d8d98-
    labels:
      k8s-app: metrics-server
      pod-template-hash: 5b4d6d8d98
      version: v0.3.1
    name: metrics-server-v0.3.1-5b4d6d8d98-6d7st
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: metrics-server-v0.3.1-5b4d6d8d98
      uid: 99e7e4e3-9217-11e9-a049-42010a8000d3
    resourceVersion: "751"
    selfLink: /api/v1/namespaces/kube-system/pods/metrics-server-v0.3.1-5b4d6d8d98-6d7st
    uid: 99e9d8ec-9217-11e9-a049-42010a8000d3
  spec:
    containers:
    - command:
      - /metrics-server
      - --metric-resolution=30s
      - --kubelet-port=10255
      - --deprecated-kubelet-completely-insecure=true
      image: k8s.gcr.io/metrics-server-amd64:v0.3.1
      imagePullPolicy: IfNotPresent
      name: metrics-server
      ports:
      - containerPort: 443
        name: https
        protocol: TCP
      resources:
        limits:
          cpu: 43m
          memory: 55Mi
        requests:
          cpu: 43m
          memory: 55Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: metrics-server-token-fvqsq
        readOnly: true
    - command:
      - /pod_nanny
      - --config-dir=/etc/config
      - --cpu=40m
      - --extra-cpu=0.5m
      - --memory=35Mi
      - --extra-memory=4Mi
      - --threshold=5
      - --deployment=metrics-server-v0.3.1
      - --container=metrics-server
      - --poll-period=300000
      - --estimator=exponential
      - --minClusterSize=5
      env:
      - name: MY_POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: MY_POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: k8s.gcr.io/addon-resizer:1.8.3
      imagePullPolicy: IfNotPresent
      name: metrics-server-nanny
      resources:
        limits:
          cpu: 100m
          memory: 300Mi
        requests:
          cpu: 5m
          memory: 50Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/config
        name: metrics-server-config-volume
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: metrics-server-token-fvqsq
        readOnly: true
    dnsPolicy: ClusterFirst
    nodeName: gke-tesg1-default-pool-ff7a1295-nvv4
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: metrics-server
    serviceAccountName: metrics-server
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: metrics-server-config
      name: metrics-server-config-volume
    - name: metrics-server-token-fvqsq
      secret:
        defaultMode: 420
        secretName: metrics-server-token-fvqsq
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:47Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:51Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:51Z
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:47Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://26cb2566c6c44c07615d6bcddfd6907e76153633eba1b81a68ff01ad69cfe078
      image: k8s.gcr.io/metrics-server-amd64:v0.3.1
      imageID: docker-pullable://k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b
      lastState: {}
      name: metrics-server
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2019-06-18T22:22:49Z
    - containerID: docker://7d2b9663bd30a51d595af2d8bfc0e240fc44ac0d1a982d769a0f1de9221e9b2f
      image: k8s.gcr.io/addon-resizer:1.8.3
      imageID: docker-pullable://k8s.gcr.io/addon-resizer@sha256:07353f7b26327f0d933515a22b1de587b040d3d85c464ea299c1b9f242529326
      lastState: {}
      name: metrics-server-nanny
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2019-06-18T22:22:49Z
    hostIP: 10.128.0.15
    phase: Running
    podIP: 10.8.2.4
    qosClass: Burstable
    startTime: 2019-06-18T22:22:47Z
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: 2019-06-18T22:22:28Z
    generateName: prometheus-to-sd-
    labels:
      controller-revision-hash: 74558c4b56
      k8s-app: prometheus-to-sd
      pod-template-generation: "1"
    name: prometheus-to-sd-bxj4q
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: prometheus-to-sd
      uid: 86c4ab08-9217-11e9-a049-42010a8000d3
    resourceVersion: "632"
    selfLink: /api/v1/namespaces/kube-system/pods/prometheus-to-sd-bxj4q
    uid: 8e69451f-9217-11e9-a049-42010a8000d3
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - gke-tesg1-default-pool-ff7a1295-7kwg
    containers:
    - command:
      - /monitor
      - --source=kube-proxy:http://localhost:10249?whitelisted=sync_proxy_rules_latency_microseconds&metricsPrefix=container.googleapis.com/internal/addons
      - --source=kubelet:http://localhost:10255?whitelisted=docker_operations,docker_operations_errors,runtime_operations,runtime_operations_errors,rest_client_requests_total,storage_operation_duration_seconds,storage_operation_errors_total,run_podsandbox_duration_seconds,run_podsandbox_errors_total
      - --stackdriver-prefix=container.googleapis.com/internal/nodes
      - --api-override=https://monitoring.googleapis.com/
      image: k8s.gcr.io/prometheus-to-sd:v0.5.0
      imagePullPolicy: IfNotPresent
      name: prometheus-to-sd
      resources:
        limits:
          cpu: 3m
          memory: 20Mi
        requests:
          cpu: 1m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: prometheus-to-sd-token-lbndt
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    nodeName: gke-tesg1-default-pool-ff7a1295-7kwg
    nodeSelector:
      beta.kubernetes.io/os: linux
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: prometheus-to-sd
    serviceAccountName: prometheus-to-sd
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - name: prometheus-to-sd-token-lbndt
      secret:
        defaultMode: 420
        secretName: prometheus-to-sd-token-lbndt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:28Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:36Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:36Z
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:28Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://591b7ebb7a08f8285cab989e86a0ab298b74953cb9a99d4132b918cadfc2857b
      image: k8s.gcr.io/prometheus-to-sd:v0.5.0
      imageID: docker-pullable://k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e
      lastState: {}
      name: prometheus-to-sd
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2019-06-18T22:22:34Z
    hostIP: 10.128.0.14
    phase: Running
    podIP: 10.128.0.14
    qosClass: Burstable
    startTime: 2019-06-18T22:22:28Z
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: 2019-06-18T22:22:26Z
    generateName: prometheus-to-sd-
    labels:
      controller-revision-hash: 74558c4b56
      k8s-app: prometheus-to-sd
      pod-template-generation: "1"
    name: prometheus-to-sd-cfn8s
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: prometheus-to-sd
      uid: 86c4ab08-9217-11e9-a049-42010a8000d3
    resourceVersion: "646"
    selfLink: /api/v1/namespaces/kube-system/pods/prometheus-to-sd-cfn8s
    uid: 8d7d773d-9217-11e9-a049-42010a8000d3
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - gke-tesg1-default-pool-ff7a1295-z7lx
    containers:
    - command:
      - /monitor
      - --source=kube-proxy:http://localhost:10249?whitelisted=sync_proxy_rules_latency_microseconds&metricsPrefix=container.googleapis.com/internal/addons
      - --source=kubelet:http://localhost:10255?whitelisted=docker_operations,docker_operations_errors,runtime_operations,runtime_operations_errors,rest_client_requests_total,storage_operation_duration_seconds,storage_operation_errors_total,run_podsandbox_duration_seconds,run_podsandbox_errors_total
      - --stackdriver-prefix=container.googleapis.com/internal/nodes
      - --api-override=https://monitoring.googleapis.com/
      image: k8s.gcr.io/prometheus-to-sd:v0.5.0
      imagePullPolicy: IfNotPresent
      name: prometheus-to-sd
      resources:
        limits:
          cpu: 3m
          memory: 20Mi
        requests:
          cpu: 1m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: prometheus-to-sd-token-lbndt
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    nodeName: gke-tesg1-default-pool-ff7a1295-z7lx
    nodeSelector:
      beta.kubernetes.io/os: linux
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: prometheus-to-sd
    serviceAccountName: prometheus-to-sd
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - name: prometheus-to-sd-token-lbndt
      secret:
        defaultMode: 420
        secretName: prometheus-to-sd-token-lbndt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:26Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:36Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:36Z
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:26Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://485cd2d44d976f42cef1c4cc70176211483a5fe1c8ebcf5a38413e7c7fcb3002
      image: k8s.gcr.io/prometheus-to-sd:v0.5.0
      imageID: docker-pullable://k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e
      lastState: {}
      name: prometheus-to-sd
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2019-06-18T22:22:33Z
    hostIP: 10.128.0.13
    phase: Running
    podIP: 10.128.0.13
    qosClass: Burstable
    startTime: 2019-06-18T22:22:26Z
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: 2019-08-14T20:40:52Z
    generateName: prometheus-to-sd-
    labels:
      controller-revision-hash: 74558c4b56
      k8s-app: prometheus-to-sd
      pod-template-generation: "1"
    name: prometheus-to-sd-dtfdm
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: prometheus-to-sd
      uid: 86c4ab08-9217-11e9-a049-42010a8000d3
    resourceVersion: "14870521"
    selfLink: /api/v1/namespaces/kube-system/pods/prometheus-to-sd-dtfdm
    uid: ce75ef62-bed3-11e9-98f3-42010a8000c4
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - gke-tesg1-default-pool-ff7a1295-dmtd
    containers:
    - command:
      - /monitor
      - --source=kube-proxy:http://localhost:10249?whitelisted=sync_proxy_rules_latency_microseconds&metricsPrefix=container.googleapis.com/internal/addons
      - --source=kubelet:http://localhost:10255?whitelisted=docker_operations,docker_operations_errors,runtime_operations,runtime_operations_errors,rest_client_requests_total,storage_operation_duration_seconds,storage_operation_errors_total,run_podsandbox_duration_seconds,run_podsandbox_errors_total
      - --stackdriver-prefix=container.googleapis.com/internal/nodes
      - --api-override=https://monitoring.googleapis.com/
      image: k8s.gcr.io/prometheus-to-sd:v0.5.0
      imagePullPolicy: IfNotPresent
      name: prometheus-to-sd
      resources:
        limits:
          cpu: 3m
          memory: 20Mi
        requests:
          cpu: 1m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: prometheus-to-sd-token-lbndt
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    nodeName: gke-tesg1-default-pool-ff7a1295-dmtd
    nodeSelector:
      beta.kubernetes.io/os: linux
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: prometheus-to-sd
    serviceAccountName: prometheus-to-sd
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - name: prometheus-to-sd-token-lbndt
      secret:
        defaultMode: 420
        secretName: prometheus-to-sd-token-lbndt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2019-08-14T20:40:52Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2019-08-14T20:40:57Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2019-08-14T20:40:57Z
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: 2019-08-14T20:40:52Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://880fcdc8bb5b584812d82173ec8f8c0e67fc2aced9bdda3224dd168d36f32b13
      image: k8s.gcr.io/prometheus-to-sd:v0.5.0
      imageID: docker-pullable://k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e
      lastState: {}
      name: prometheus-to-sd
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2019-08-14T20:40:57Z
    hostIP: 10.128.0.17
    phase: Running
    podIP: 10.128.0.17
    qosClass: Burstable
    startTime: 2019-08-14T20:40:52Z
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: 2019-08-14T18:17:23Z
    generateName: prometheus-to-sd-
    labels:
      controller-revision-hash: 74558c4b56
      k8s-app: prometheus-to-sd
      pod-template-generation: "1"
    name: prometheus-to-sd-mc682
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: prometheus-to-sd
      uid: 86c4ab08-9217-11e9-a049-42010a8000d3
    resourceVersion: "14842882"
    selfLink: /api/v1/namespaces/kube-system/pods/prometheus-to-sd-mc682
    uid: c33fb009-bebf-11e9-98f3-42010a8000c4
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - gke-tesg1-default-pool-ff7a1295-zpc5
    containers:
    - command:
      - /monitor
      - --source=kube-proxy:http://localhost:10249?whitelisted=sync_proxy_rules_latency_microseconds&metricsPrefix=container.googleapis.com/internal/addons
      - --source=kubelet:http://localhost:10255?whitelisted=docker_operations,docker_operations_errors,runtime_operations,runtime_operations_errors,rest_client_requests_total,storage_operation_duration_seconds,storage_operation_errors_total,run_podsandbox_duration_seconds,run_podsandbox_errors_total
      - --stackdriver-prefix=container.googleapis.com/internal/nodes
      - --api-override=https://monitoring.googleapis.com/
      image: k8s.gcr.io/prometheus-to-sd:v0.5.0
      imagePullPolicy: IfNotPresent
      name: prometheus-to-sd
      resources:
        limits:
          cpu: 3m
          memory: 20Mi
        requests:
          cpu: 1m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: prometheus-to-sd-token-lbndt
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    nodeName: gke-tesg1-default-pool-ff7a1295-zpc5
    nodeSelector:
      beta.kubernetes.io/os: linux
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: prometheus-to-sd
    serviceAccountName: prometheus-to-sd
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - name: prometheus-to-sd-token-lbndt
      secret:
        defaultMode: 420
        secretName: prometheus-to-sd-token-lbndt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2019-08-14T18:17:24Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2019-08-14T18:17:28Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2019-08-14T18:17:28Z
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: 2019-08-14T18:17:24Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://668b3c6383992b6da5d7d2d04afca305b3dcdf796790011ab461b60c740db43c
      image: k8s.gcr.io/prometheus-to-sd:v0.5.0
      imageID: docker-pullable://k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e
      lastState: {}
      name: prometheus-to-sd
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2019-08-14T18:17:27Z
    hostIP: 10.128.0.16
    phase: Running
    podIP: 10.128.0.16
    qosClass: Burstable
    startTime: 2019-08-14T18:17:24Z
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: 2019-06-18T22:22:26Z
    generateName: prometheus-to-sd-
    labels:
      controller-revision-hash: 74558c4b56
      k8s-app: prometheus-to-sd
      pod-template-generation: "1"
    name: prometheus-to-sd-w8hsj
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: prometheus-to-sd
      uid: 86c4ab08-9217-11e9-a049-42010a8000d3
    resourceVersion: "622"
    selfLink: /api/v1/namespaces/kube-system/pods/prometheus-to-sd-w8hsj
    uid: 8d9a319b-9217-11e9-a049-42010a8000d3
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - gke-tesg1-default-pool-ff7a1295-nvv4
    containers:
    - command:
      - /monitor
      - --source=kube-proxy:http://localhost:10249?whitelisted=sync_proxy_rules_latency_microseconds&metricsPrefix=container.googleapis.com/internal/addons
      - --source=kubelet:http://localhost:10255?whitelisted=docker_operations,docker_operations_errors,runtime_operations,runtime_operations_errors,rest_client_requests_total,storage_operation_duration_seconds,storage_operation_errors_total,run_podsandbox_duration_seconds,run_podsandbox_errors_total
      - --stackdriver-prefix=container.googleapis.com/internal/nodes
      - --api-override=https://monitoring.googleapis.com/
      image: k8s.gcr.io/prometheus-to-sd:v0.5.0
      imagePullPolicy: IfNotPresent
      name: prometheus-to-sd
      resources:
        limits:
          cpu: 3m
          memory: 20Mi
        requests:
          cpu: 1m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: prometheus-to-sd-token-lbndt
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    nodeName: gke-tesg1-default-pool-ff7a1295-nvv4
    nodeSelector:
      beta.kubernetes.io/os: linux
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: prometheus-to-sd
    serviceAccountName: prometheus-to-sd
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - name: prometheus-to-sd-token-lbndt
      secret:
        defaultMode: 420
        secretName: prometheus-to-sd-token-lbndt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:27Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:36Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:36Z
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: 2019-06-18T22:22:27Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://6b05c154ed651c29b8f60f16e07a9946e4fe74d6b934986b5eed0aaf9f51e91c
      image: k8s.gcr.io/prometheus-to-sd:v0.5.0
      imageID: docker-pullable://k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e
      lastState: {}
      name: prometheus-to-sd
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2019-06-18T22:22:35Z
    hostIP: 10.128.0.15
    phase: Running
    podIP: 10.128.0.15
    qosClass: Burstable
    startTime: 2019-06-18T22:22:27Z
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
